{"google":"","tagline":"python daemon that munches on logs and sends their contents to logstash","note":"Don't delete this file! It's used internally to help with page regeneration.","name":"Beaver","body":"Requirements\r\n============\r\n\r\n* Python 2.7 (untested on other versions)\r\n* Optional zeromq support: install libzmq (``brew install zmq`` or ``apt-get install libzmq-dev``) and pyzmq (``pip install pyzmq==2.1.11``)\r\n\r\nInstallation\r\n============\r\n\r\nUsing PIP:\r\n\r\nFrom Github::\r\n\r\n    pip install git+git://github.com/josegonzalez/beaver.git#egg=beaver\r\n\r\nFrom PyPI::\r\n\r\n    pip install beaver==11\r\n\r\nUsage\r\n=====\r\n\r\nusage::\r\n\r\n    beaver [-h] [-m {bind,connect}] [-p PATH] [-f FILES [FILES ...]]\r\n              [-t {rabbitmq,redis,stdout,zmq,udp}] [-c CONFIG] [-d DEBUG] [--fqdn]\r\n\r\noptional arguments::\r\n\r\n    -h, --help            show this help message and exit\r\n    -m {bind,connect}, --mode {bind,connect}\r\n                        bind or connect mode\r\n    -p PATH, --path PATH  path to log files\r\n    -f FILES [FILES ...], --files FILES [FILES ...]\r\n                        space-separated filelist to watch, can include globs\r\n                        (*.log). Overrides --path argument\r\n    -t {rabbitmq,redis,stdout,zmq}, --transport {rabbitmq,redis,stdout,zmq}\r\n                        log transport method\r\n    -c CONFIG, --configfile CONFIG\r\n                        ini config file path\r\n    -d DEBUG, --debug DEBUG\r\n                        enable debug mode\r\n    --fqdn\r\n                        use the machine's FQDN for source_host\r\n\r\nBackground\r\n==========\r\n\r\nBeaver provides an lightweight method for shipping local log files to Logstash. It does this using either redis, stdin, zeromq as the transport. This means you'll need a redis, stdin, zeromq input somewhere down the road to get the events.\r\n\r\nEvents are sent in logstash's ``json_event`` format. Options can also be set as environment variables.\r\n\r\nNOTE: the redis transport uses a namespace of ``logstash:beaver`` by default.  You will need to update your logstash indexer to match this.\r\n\r\nExamples\r\n--------\r\n\r\nExample 1: Listen to all files in the default path of /var/log on standard out as json::\r\n\r\n    beaver\r\n\r\nExample 2: Listen to all files in the default path of /var/log on standard out with msgpack::\r\n\r\n    BEAVER_FORMAT='msgpack' beaver\r\n\r\nExample 3: Listen to all files in the default path of /var/log on standard out as a string::\r\n\r\n    BEAVER_FORMAT='string' beaver\r\n\r\nExample 4: Sending logs from /var/log files to a redis list::\r\n\r\n    REDIS_URL='redis://localhost:6379/0' beaver -t redis\r\n\r\nExample 5: Use environment variables to send logs from /var/log files to a redis list::\r\n\r\n    REDIS_URL='redis://localhost:6379/0' BEAVER_PATH='/var/log' BEAVER_TRANSPORT=redis beaver\r\n\r\nExample 6: Zeromq listening on port 5556 (all interfaces)::\r\n\r\n    ZEROMQ_ADDRESS='tcp://*:5556' beaver -m bind -t zmq\r\n\r\n    # logstash config:\r\n    input {\r\n      zeromq {\r\n        type => 'shipper-input'\r\n        mode => 'client'\r\n        topology => 'pushpull'\r\n        address => 'tcp://shipperhost:5556'\r\n      }\r\n    }\r\n    output { stdout { debug => true } }\r\n\r\nExample 7: Zeromq connecting to remote port 5556 on indexer::\r\n\r\n    ZEROMQ_ADDRESS='tcp://indexer:5556' beaver -m connect -t zmq\r\n\r\n    # logstash config:\r\n    input {\r\n      zeromq {\r\n        type => 'shipper-input'\r\n        mode => 'server'\r\n        topology => 'pushpull'\r\n        address => 'tcp://*:5556'\r\n      }\r\n    }\r\n    output { stdout { debug => true } }\r\n\r\nExample 8: Real-world usage of Redis as a transport::\r\n\r\n    # in /etc/hosts\r\n    192.168.0.10 redis-internal\r\n\r\n    # From the commandline\r\n    REDIS_NAMESPACE='app:unmappable' REDIS_URL='redis://redis-internal:6379/0' beaver -f /var/log/unmappable.log -t redis\r\n\r\n    # logstash indexer config:\r\n    input {\r\n      redis {\r\n        host => 'redis-internal'\r\n        data_type => 'list'\r\n        key => 'app:unmappable'\r\n        type => 'app:unmappable'\r\n      }\r\n    }\r\n    output { stdout { debug => true } }\r\n\r\nAs you can see, ``beaver`` is pretty flexible as to how you can use/abuse it in production.\r\n\r\nExample 9: RabbitMQ connecting to defaults on remote broker::\r\n\r\n    # From the commandline\r\n    RABBITMQ_HOST='10.0.0.1' beaver -t rabbitmq\r\n\r\n    # logstash config:\r\n    input { amqp {\r\n        name => 'logstash-queue'\r\n        type => 'direct'\r\n        host => '10.0.0.1'\r\n        exchange => 'logstash-exchange'\r\n        key => 'logstash-key'\r\n        exclusive => false\r\n        durable => false\r\n        auto_delete => false\r\n      }\r\n    }\r\n    output { stdout { debug => true } }\r\n\r\nExample 10: Read config from config.ini and put to stdout::\r\n\r\n    # From the commandline\r\n    beaver -c config.ini -t stdout\r\n\r\n    # config.ini content:\r\n    [/tmp/somefile]\r\n    type: mytype\r\n    tags: tag1,tag2\r\n    add_field: fieldname1,fieldvalue1[,fieldname2,fieldvalue2, ...]\r\n\r\n    [/var/log/*log]\r\n    type: syslog\r\n    tags: sys\r\n\r\n    [/var/log/{secure,messages}.log]\r\n    type: syslog\r\n    tags: sys\r\n\r\nExample 11: UDP transport::\r\n\r\n    # From the commandline\r\n    UDP_HOST='127.0.0.1' UDP_PORT='9999' beaver -t udp\r\n\r\n    # logstash config:\r\n    input {\r\n      udp {\r\n        type => 'shipper-input'\r\n        host => '127.0.0.1'\r\n        port => '9999'\r\n      }\r\n    }\r\n    output { stdout { debug => true } }\r\n\r\nTodo\r\n====\r\n\r\n* Use python threading + subprocess in order to support usage of ``yield`` across all operating systems\r\n* Fix usage on non-linux platforms - file.readline() does not work as expected on OS X. See above for potential solution\r\n* More transports\r\n* ~Ability to specify files, tags, and other metadata within a configuration file~\r\n\r\nCaveats\r\n=======\r\n\r\nWhen using ``copytruncate`` style log rotation, two race conditions can occur:\r\n\r\n1. Any log data written prior to truncation which beaver has not yet\r\n   read and processed is lost. Nothing we can do about that.\r\n\r\n2. Should the file be truncated, rewritten, and end up being larger than\r\n   the original file during the sleep interval, beaver won't detect\r\n   this. After some experimentation, this behavior also exists in GNU\r\n   tail, so I'm going to call this a \"don't do that then\" bug :)\r\n\r\n   Additionally, the files beaver will most likely be called upon to\r\n   watch which may be truncated are generally going to be large enough\r\n   and slow-filling enough that this won't crop up in the wild.\r\n\r\n\r\nCredits\r\n=======\r\n\r\nBased on work from Giampaolo and Lusis::\r\n\r\n    Real time log files watcher supporting log rotation.\r\n\r\n    Original Author: Giampaolo Rodola' <g.rodola [AT] gmail [DOT] com>\r\n    http://code.activestate.com/recipes/577968-log-watcher-tail-f-log/\r\n\r\n    License: MIT\r\n\r\n    Other hacks (ZMQ, JSON, optparse, ...): lusis\r\n"}